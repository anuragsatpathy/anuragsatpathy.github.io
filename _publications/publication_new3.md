---
title: "LBA: Matching Theory Based Latency-Sensitive Binary Offloading in IoT-Fog Networks"
collection: publications
permalink: /publications/publication_new3
excerpt: "This work studies the performance of spot instances via rigorous experimentation over commercial SPs such as Amazon AWS and Microsoft Azure. Real-world evaluations affirm that spot instances perform poorly compared to their on-demand counterpart concerning memory, CPU, disk read, and write operations."
date: 2023-11-07
venue: 'Workshop on Machine Intelligence in Networked Data and Systems (MINDS)'
classes: wide
---
## Authors
Priyanka Soni, Omkar Chand Deshlahre, Sourav Kanti Addya, and **Anurag Satpathy**

## Conference
*2024 16th International Conference on Communication Systems & Networks* (COMSNETS), **(Core Ranking - National India)**

## Abstract
The Internet of Things (IoT) is growing more popular with applications like healthcare services, traffic monitoring, video streaming, smart homes, etc. These applications produce an enormous amount of data, so a realistic option in this instance is to offload computational tasks to their proximity fog nodes (FNs)  instead of the remote cloud. However, a negligent offloading strategy may cause anomalous computational traffic load at the FNs, causing congestion that may adversely affect the latency. However, the latency of task flows from IoT devices comprises communications latency at BS and computational latency at FNs. Therefore, it's crucial to design offloading algorithms to distribute the computational load at FN evenly and efficiently utilize the FN resources. To solve this problem, we proposed LBA in a fog network with a binary offloading strategy using the matching theory-based approach.  We utilize the Analytic Hierarchy Process (AHP) to generate the preference list. Furthermore, the binary offloading technique follows the deferred acceptance algorithm (DAA) to produce a stable assignment, and the complete offloading problem is modeled as a one-to-many matching game. Comprehensive simulations ensure that LBA can accomplish a better-balanced assignment for homogeneous and heterogeneous input concerning all the baseline algorithms.

[Download Paper Here]
